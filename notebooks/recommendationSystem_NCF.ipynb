{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca123944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "class NeuralCF(nn.Module): \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, n_factors)\n",
    "        self.item_embedding = nn.Embedding(n_items, n_factors)\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(n_factors * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        user_emb = self.user_embedding(user_id)\n",
    "        item_emb = self.item_embedding(item_id)\n",
    "        x = torch.cat([user_emb, item_emb], dim=1)\n",
    "        out = self.fc_layers(x)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e276f191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3458c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304a9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c217e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d46eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"\"\"To ensure anonymity, a unique identifier (GUID) is generated for each customer, replacing the actual names.\n",
    "\n",
    "An age is randomly assigned to each user based on a valid range that corresponds to their customer type (e.g., a \"student\" might be between 18–25 years old, while a \"young adult\" may fall within 22–35).\n",
    "\n",
    "The gender of each customer is inferred by splitting the Customer Name into first and last names. The first name is then passed to a large language model (LLM), which predicts the likely gender. This predicted gender is recorded in the gender column.\"\"\"\n",
    "\n",
    "str2 = \"\"\"To ensure anonymity, a unique identifier (GUID) is generated for each customer, replacing the actual names.\n",
    "\n",
    "An age is randomly assigned to each user based on a valid range that corresponds to their customer type (e.g., a \"student\" might be between 18–25 years old, while a \"young adult\" may fall within 22–35).\n",
    "\n",
    "The gender of each customer is inferred by splitting the Customer Name into first and last names. The first name is then passed to a large language model (LLM), which predicts the likely gender. This predicted gender is recorded in the gender column.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e823d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal\n"
     ]
    }
   ],
   "source": [
    "if str1.lower() == str2.lower():\n",
    "    print(\"Equal\")\n",
    "else:\n",
    "    print(\"Not Equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c146bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to ensure anonymity, a unique identifier (guid) is generated for each customer, replacing the actual names.\n",
      "\n",
      "an age is randomly assigned to each user based on a valid range that corresponds to their customer type (e.g., a \"student\" might be between 18–25 years old, while a \"young adult\" may fall within 22–35).\n",
      "\n",
      "the gender of each customer is inferred by splitting the customer name into first and last names. the first name is then passed to a large language model (llm), which predicts the likely gender. this predicted gender is recorded in the gender column.\n"
     ]
    }
   ],
   "source": [
    "print(str1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dcd5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
