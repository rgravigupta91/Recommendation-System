{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8hh2Fsqv9nG",
        "outputId": "386c76d7-28a3-43bf-ae61-10cc35f105ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.0000\n",
            "Recall@5: 1.0000\n",
            "Recall@20: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\"\"\" \n",
        "# Load your user metadata\n",
        "df_users = pd.read_csv(\"UserData.csv\")\n",
        "df_users['user_id'] = df_users['guid'].astype('category').cat.codes\n",
        " \n",
        "# Simulate product catalog\n",
        "products = {\n",
        "    'item_id': [101, 102, 103, 104, 105],\n",
        "    'description': [\n",
        "        \"yoga mat non-slip fitness\",\n",
        "        \"protein bar organic vegan\",\n",
        "        \"home gym treadmill exercise\",\n",
        "        \"smartwatch health fitness\",\n",
        "        \"running shoes lightweight\"\n",
        "    ]\n",
        "}\n",
        "df_products = pd.DataFrame(products)\n",
        "\n",
        "# Simulate interactions\n",
        "interactions = []\n",
        "for user_id in df_users['user_id']:\n",
        "    liked_items = np.random.choice(df_products['item_id'], size=2, replace=False)\n",
        "    for item in liked_items:\n",
        "        interactions.append({'user_id': user_id, 'item_id': item, 'rating': 1})\n",
        "#df_interact = pd.DataFrame(interactions)\"\"\"\n",
        "df_interact = pd.read_csv('../data/UserItemData.csv')\n",
        "# TF-IDF over product descriptions\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df_products['description'])\n",
        "cos_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# Recommendation function\n",
        "def recommend(user_id, k=5):\n",
        "    rated_items = df_interact[df_interact['user_id'] == user_id]['item_id'].values\n",
        "    if len(rated_items) == 0:\n",
        "        return []\n",
        "\n",
        "    scores = np.zeros(len(df_products))\n",
        "    for item in rated_items:\n",
        "        idx = df_products[df_products['item_id'] == item].index[0]\n",
        "        scores += cos_sim[idx]\n",
        "\n",
        "    rated_idxs = [df_products[df_products['item_id'] == i].index[0] for i in rated_items]\n",
        "    scores[rated_idxs] = 0  # mask already rated\n",
        "\n",
        "    top_indices = np.argsort(scores)[::-1][:k]\n",
        "    return df_products.iloc[top_indices]['item_id'].tolist()\n",
        "\n",
        "# Evaluate\n",
        "y_true, y_pred = [], []\n",
        "recall_5, recall_20 = [], []\n",
        "\n",
        "for user_id in df_users['user_id'].unique():\n",
        "    true_items = df_interact[df_interact['user_id'] == user_id]['item_id'].values\n",
        "    top5 = recommend(user_id, k=5)\n",
        "    top20 = recommend(user_id, k=20)\n",
        "\n",
        "    # Recall\n",
        "    recall_5.append(len(set(true_items) & set(top5)) / len(true_items))\n",
        "    recall_20.append(len(set(true_items) & set(top20)) / len(true_items))\n",
        "\n",
        "    # Binary prediction for RMSE\n",
        "    for item in true_items:\n",
        "        y_true.append(1)\n",
        "        y_pred.append(1 if item in top5 else 0)\n",
        "\n",
        "# Metrics\n",
        "rmse = root_mean_squared_error(y_true, y_pred)\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"Recall@5: {np.mean(recall_5):.4f}\")\n",
        "print(f\"Recall@20: {np.mean(recall_20):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQxZgaalwnUv",
        "outputId": "39e0dbb7-5581-41b7-e652-8c4841621856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF Results:\n",
            "RMSE: 0.7746\n",
            "Precision@10: 0.4000\n",
            "Recall@10: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import root_mean_squared_error, precision_score, recall_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import defaultdict\n",
        "\n",
        "# ---------- Simulated Sample Dataset ----------\n",
        "users = ['U1', 'U2', 'U3', 'U4']\n",
        "items = [101, 102, 103, 104, 105]\n",
        "descriptions = [\n",
        "    \"yoga mat non-slip fitness gym\",\n",
        "    \"protein bar organic energy\",\n",
        "    \"home gym treadmill workout\",\n",
        "    \"smartwatch fitness tracker health\",\n",
        "    \"lightweight running shoes sport\"\n",
        "]\n",
        "\n",
        "interactions = [\n",
        "    ('U1', 101, 1), ('U1', 102, 1),\n",
        "    ('U2', 101, 1), ('U2', 103, 1),\n",
        "    ('U3', 104, 1), ('U3', 105, 1),\n",
        "    ('U4', 102, 1), ('U4', 104, 1)\n",
        "]\n",
        "\n",
        "df_items = pd.DataFrame({'item_id': items, 'description': descriptions})\n",
        "df_interact = pd.DataFrame(interactions, columns=['user_id', 'item_id', 'rating'])\n",
        "\n",
        "# ---------- TF-IDF Encoding ----------\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df_items['description'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# ---------- Create Recommendation Function ----------\n",
        "def recommend_tfidf(user_id, top_k=10):\n",
        "    rated_items = df_interact[df_interact['user_id'] == user_id]['item_id'].tolist()\n",
        "    if not rated_items:\n",
        "        return []\n",
        "\n",
        "    scores = np.zeros(len(df_items))\n",
        "    for item in rated_items:\n",
        "        idx = df_items[df_items['item_id'] == item].index[0]\n",
        "        scores += cosine_sim[idx]\n",
        "\n",
        "    rated_indices = [df_items[df_items['item_id'] == i].index[0] for i in rated_items]\n",
        "    scores[rated_indices] = 0  # Mask known items\n",
        "\n",
        "    top_indices = scores.argsort()[::-1][:top_k]\n",
        "    return df_items.iloc[top_indices]['item_id'].tolist()\n",
        "\n",
        "# ---------- Evaluation ----------\n",
        "y_true_all = []\n",
        "y_pred_all = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "\n",
        "for user in df_interact['user_id'].unique():\n",
        "    true_items = df_interact[df_interact['user_id'] == user]['item_id'].tolist()\n",
        "    rec_items = recommend_tfidf(user, top_k=10)\n",
        "\n",
        "    y_true = [1 if item in true_items else 0 for item in rec_items]\n",
        "    y_pred = [1] * len(y_true)\n",
        "\n",
        "    y_true_all += y_true\n",
        "    y_pred_all += y_pred\n",
        "\n",
        "    # Per-user metrics\n",
        "    intersection = len(set(true_items) & set(rec_items))\n",
        "    precision = intersection / len(rec_items) if rec_items else 0\n",
        "    recall = intersection / len(true_items) if true_items else 0\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "\n",
        "# ---------- Metrics ----------\n",
        "rmse = root_mean_squared_error(y_true_all, y_pred_all)\n",
        "precision_at_10 = np.mean(precision_list)\n",
        "recall_at_10 = np.mean(recall_list)\n",
        "\n",
        "print(f\"TF-IDF Results:\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"Precision@10: {precision_at_10:.4f}\")\n",
        "print(f\"Recall@10: {recall_at_10:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Cx9z1FrVAzg4",
        "outputId": "b097a7a8-5dcd-482b-c830-35835b9c3e86"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-850350481.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_users\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtrue_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_interact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_interact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mrec_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommend_tfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrue_items\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrec_items\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-850350481.py\u001b[0m in \u001b[0;36mrecommend_tfidf\u001b[0;34m(user_id, top_k)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrated_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4091\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4093\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4095\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \"\"\"\n\u001b[0;32m-> 4153\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4131\u001b[0m             )\n\u001b[1;32m   4132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4133\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   4134\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4135\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexers/utils.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py\u001b[0m in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "\n",
        "# Load user metadata\n",
        "df_users = pd.read_csv(\"UserData.csv\")\n",
        "df_users['user_id'] = df_users['guid'].astype('category').cat.codes\n",
        "\n",
        "# Load item data\n",
        "df_items = pd.read_csv(\"BigBasket Products.csv\")\n",
        "\n",
        "# Make sure there's a product description column (you can adjust as needed)\n",
        "desc_col = 'product'  # Change if your column is named differently\n",
        "df_items['item_id'] = df_items.index\n",
        "\n",
        "# Simulate user-item interactions\n",
        "interactions = []\n",
        "np.random.seed(42)\n",
        "for user_id in df_users['user_id']:\n",
        "    liked_items = np.random.choice(df_items['item_id'], size=2, replace=False)\n",
        "    for item in liked_items:\n",
        "        interactions.append({'user_id': user_id, 'item_id': item, 'rating': 1})\n",
        "df_interact = pd.DataFrame(interactions)\n",
        "\n",
        "# TF-IDF vectorization on product descriptions\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(df_items[desc_col].astype(str))\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# Recommendation function\n",
        "def recommend_tfidf(user_id, top_k=10):\n",
        "    rated_items = df_interact[df_interact['user_id'] == user_id]['item_id'].tolist()\n",
        "    if not rated_items:\n",
        "        return []\n",
        "\n",
        "    scores = np.zeros(len(df_items))\n",
        "    for item in rated_items:\n",
        "        idx = df_items[df_items['item_id'] == item].index[0]\n",
        "        scores += cosine_sim[idx]\n",
        "\n",
        "    rated_indices = [df_items[df_items['item_id'] == i].index[0] for i in rated_items]\n",
        "    scores[rated_indices] = 0\n",
        "\n",
        "    top_indices = scores.argsort()[::-1][:top_k]\n",
        "    return df_items.iloc[top_indices]['item_id'].tolist()\n",
        "\n",
        "# Evaluate RMSE, Precision@10, Recall@10\n",
        "y_true_all, y_pred_all = [], []\n",
        "precision_list, recall_list = [], []\n",
        "\n",
        "for user in df_users['user_id'].unique():\n",
        "    true_items = df_interact[df_interact['user_id'] == user]['item_id'].tolist()\n",
        "    rec_items = recommend_tfidf(user, top_k=10)\n",
        "\n",
        "    y_true = [1 if item in true_items else 0 for item in rec_items]\n",
        "    y_pred = [1] * len(y_true)\n",
        "\n",
        "    y_true_all += y_true\n",
        "    y_pred_all += y_pred\n",
        "\n",
        "    intersection = len(set(true_items) & set(rec_items))\n",
        "    precision = intersection / len(rec_items) if rec_items else 0\n",
        "    recall = intersection / len(true_items) if true_items else 0\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "\n",
        "# Output metrics\n",
        "rmse = root_mean_squared_error(y_true_all, y_pred_all)\n",
        "precision_at_10 = np.mean(precision_list)\n",
        "recall_at_10 = np.mean(recall_list)\n",
        "\n",
        "print(f\"\\nTF-IDF Recommendation Results:\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"Precision@10: {precision_at_10:.4f}\")\n",
        "print(f\"Recall@10: {recall_at_10:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Jw3awdGuDx",
        "outputId": "1f6a1030-4479-4d7b-daac-d7cc93420c6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7420/7420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 6.9257e-08\n",
            "Epoch 2/10\n",
            "\u001b[1m7420/7420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4ms/step - loss: 3.2343e-08 - val_loss: 1.7328e-09\n",
            "Epoch 3/10\n",
            "\u001b[1m7420/7420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4ms/step - loss: 8.7595e-10 - val_loss: 9.7709e-11\n",
            "Epoch 4/10\n",
            "\u001b[1m7420/7420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - loss: 6.0205e-11 - val_loss: 2.2887e-11\n",
            "Epoch 5/10\n",
            "\u001b[1m7420/7420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - loss: 1.7463e-11 - val_loss: 1.1870e-11\n",
            "Epoch 6/10\n",
            "\u001b[1m7420/7420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - loss: 9.7570e-12 - val_loss: 7.9662e-12\n",
            "Epoch 7/10\n",
            "\u001b[1m7420/7420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - loss: 6.7711e-12 - val_loss: 5.9796e-12\n",
            "Epoch 8/10\n",
            "\u001b[1m7420/7420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - loss: 5.1590e-12 - val_loss: 4.7808e-12\n",
            "Epoch 9/10\n",
            "\u001b[1m7420/7420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - loss: 4.1750e-12 - val_loss: 3.9799e-12\n",
            "Epoch 10/10\n",
            "\u001b[1m7420/7420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - loss: 3.4853e-12 - val_loss: 3.4060e-12\n",
            "\n",
            "✅ NCF RMSE: 0.0000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "\n",
        "# ✅ Load and process UserData.csv\n",
        "df_users = pd.read_csv(\"UserData.csv\")\n",
        "df_users['user_id'] = df_users['guid'].astype(\"category\").cat.codes\n",
        "\n",
        "# ✅ Load and process BigBasket Products.csv\n",
        "df_items = pd.read_csv(\"BigBasket Products.csv\")\n",
        "df_items['item_id'] = df_items.index  # Create numeric ID\n",
        "\n",
        "# ✅ Simulate binary interactions (likes)\n",
        "interactions = []\n",
        "np.random.seed(42)\n",
        "for user_id in df_users['user_id']:\n",
        "    liked = np.random.choice(df_items['item_id'], size=2, replace=False)\n",
        "    for item in liked:\n",
        "        interactions.append({'user_id': user_id, 'item_id': item, 'rating': 1})\n",
        "df = pd.DataFrame(interactions)\n",
        "\n",
        "# ✅ Create unique numeric values\n",
        "num_users = df['user_id'].nunique()\n",
        "num_items = df['item_id'].nunique()\n",
        "\n",
        "# ✅ Train-test split\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Convert to arrays for TensorFlow\n",
        "X_train_user = np.array(train['user_id'])\n",
        "X_train_item = np.array(train['item_id'])\n",
        "y_train = np.array(train['rating'])\n",
        "\n",
        "X_test_user = np.array(test['user_id'])\n",
        "X_test_item = np.array(test['item_id'])\n",
        "y_test = np.array(test['rating'])\n",
        "\n",
        "# ✅ Build the NCF model with GPU context\n",
        "with tf.device('/GPU:0'):\n",
        "    user_input = tf.keras.layers.Input(shape=(1,))\n",
        "    item_input = tf.keras.layers.Input(shape=(1,))\n",
        "\n",
        "    user_vec = tf.keras.layers.Embedding(input_dim=num_users, output_dim=32)(user_input)\n",
        "    item_vec = tf.keras.layers.Embedding(input_dim=num_items, output_dim=32)(item_input)\n",
        "\n",
        "    user_vec = tf.keras.layers.Flatten()(user_vec)\n",
        "    item_vec = tf.keras.layers.Flatten()(item_vec)\n",
        "\n",
        "    x = tf.keras.layers.Concatenate()([user_vec, item_vec])\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[user_input, item_input], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# ✅ Train\n",
        "model.fit([X_train_user, X_train_item], y_train,\n",
        "          batch_size=64,\n",
        "          epochs=10,\n",
        "          validation_split=0.1,\n",
        "          verbose=1)\n",
        "\n",
        "# ✅ RMSE on test\n",
        "test_preds = model.predict([X_test_user, X_test_item], verbose=0)\n",
        "rmse = root_mean_squared_error(y_test, test_preds)\n",
        "print(f\"\\n✅ NCF RMSE: {rmse:.4f}\")\n",
        "\n",
        "# ✅ Precision@10 and Recall@10\n",
        "all_preds = defaultdict(list)\n",
        "for user in df_users['user_id']:\n",
        "    items = df_items['item_id'].tolist()\n",
        "    user_vec = [user] * len(items)\n",
        "    preds = model.predict([np.array(user_vec), np.array(items)], verbose=0).flatten()\n",
        "    top_items = np.argsort(preds)[::-1][:10]\n",
        "    all_preds[user] = [items[i] for i in top_items]\n",
        "\n",
        "precision_list, recall_list = [], []\n",
        "for user in df_users['user_id']:\n",
        "    true_items = df[df['user_id'] == user]['item_id'].tolist()\n",
        "    pred_items = all_preds[user]\n",
        "    intersection = len(set(pred_items) & set(true_items))\n",
        "    precision = intersection / 10\n",
        "    recall = intersection / len(true_items) if true_items else 0\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "\n",
        "print(f\"✅ Precision@10: {np.mean(precision_list):.4f}\")\n",
        "print(f\"✅ Recall@10: {np.mean(recall_list):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3KA9T4AH39e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
